#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Misiddons Book Database â€“ Streamlit app (Form + Scanner)
- Add books manually via form
- Scan barcodes from a photo to autoâ€‘fill metadata (title, author, cover, description)
- Add to Library or Wishlist
- Prevents duplicates (by ISBN or Title+Author)
- ENHANCEMENTS (this build):
Â  Â  - Search bar for filtering books
Â  Â  - Improved feedback messages
Â  Â  - Recommendations: two modes
Â  Â  Â  Â  â€¢ By author (Google first, OpenLibrary fallback, filters out owned)
Â  Â  Â  Â  â€¢ Surprise me (4 random unseen picks across your authors)
Â  Â  - More readable DataFrame display
Â  Â  - Authors' names with special characters handled
Â  Â  - Statistics (metrics only, no chart)
Â  Â  - Extra robustness in Google/OpenLibrary fetchers
Â  Â  - Photo upload barcode scanner
Â  Â  - NEW: Interactive Data Deep-Clean & Repair tool
"""
from __future__ import annotations

import random
import re
import unicodedata
from difflib import SequenceMatcher

import pandas as pd
import requests
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
from urllib.parse import quote
from PIL import Image
from gspread.exceptions import APIError, WorksheetNotFound

# Optional barcode support
try:
Â  Â  from pyzbar.pyzbar import decode as zbar_decode
except Exception:Â  # pyzbar/libzbar not available in some envs
Â  Â  zbar_decode = None

# ---------- CONFIG ----------
DEFAULT_SHEET_ID = "1AXupO4-kABwoz88H2dYfc6hv6wzooh7f8cDnIRl0Q7s"
SPREADSHEET_ID = st.secrets.get("google_sheet_id", DEFAULT_SHEET_ID)
GOOGLE_SHEET_NAME = st.secrets.get("google_sheet_name", "database")Â  # only used if no ID
GOOGLE_BOOKS_KEY = st.secrets.get("google_books_api_key", None)

st.set_page_config(page_title="Misiddons Book Database", layout="wide")

UA = {"User-Agent": "misiddons/1.2"} # Version bump for new feature

# ---------- Google Sheets helpers ----------
@st.cache_resource
def connect_to_gsheets():
Â  Â  if "gcp_service_account" not in st.secrets:
Â  Â  Â  Â  st.error("gcp_service_account not found in secrets. Add your service account JSON there.")
Â  Â  Â  Â  return None
Â  Â  try:
Â  Â  Â  Â  scopes = [
Â  Â  Â  Â  Â  Â  "https://www.googleapis.com/auth/spreadsheets",
Â  Â  Â  Â  Â  Â  "https://www.googleapis.com/auth/drive.readonly",
Â  Â  Â  Â  ]
Â  Â  Â  Â  creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
Â  Â  Â  Â  return gspread.authorize(creds)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Failed to authorize Google Sheets: {e}")
Â  Â  Â  Â  return None

@st.cache_data(ttl=60)
def load_data(worksheet: str) -> pd.DataFrame:
Â  Â  """Fetch a worksheet into a DataFrame. Falls back to get_all_values()."""
Â  Â  client_local = connect_to_gsheets()
Â  Â  if not client_local:
Â  Â  Â  Â  return pd.DataFrame()
Â  Â  try:
Â  Â  Â  Â  ss = client_local.open_by_key(SPREADSHEET_ID) if SPREADSHEET_ID else client_local.open(GOOGLE_SHEET_NAME)
Â  Â  Â  Â  target = worksheet.strip()
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  ws = ss.worksheet(target)
Â  Â  Â  Â  except WorksheetNotFound:
Â  Â  Â  Â  Â  Â  names = [w.title for w in ss.worksheets()]
Â  Â  Â  Â  Â  Â  norm = {n.strip().casefold(): n for n in names}
Â  Â  Â  Â  Â  Â  if target.strip().casefold() in norm:
Â  Â  Â  Â  Â  Â  Â  Â  ws = ss.worksheet(norm[target.strip().casefold()])
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  raise
Â  Â  Â  Â  # Try fast path first
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  df = pd.DataFrame(ws.get_all_records())
Â  Â  Â  Â  Â  Â  return df.dropna(how="all")
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  vals = ws.get_all_values()
Â  Â  Â  Â  Â  Â  if not vals:
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  Â  Â  header, *rows = vals
Â  Â  Â  Â  Â  Â  return pd.DataFrame(rows, columns=header).dropna(how="all")
Â  Â  except WorksheetNotFound:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  client = connect_to_gsheets()
Â  Â  Â  Â  Â  Â  ss = client.open_by_key(SPREADSHEET_ID) if client and SPREADSHEET_ID else None
Â  Â  Â  Â  Â  Â  tabs = [w.title for w in ss.worksheets()] if ss else []
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  tabs = []
Â  Â  Â  Â  st.error(f"Worksheet '{worksheet}' not found. Available tabs: {tabs}")
Â  Â  Â  Â  return pd.DataFrame()
Â  Â  except APIError as e:
Â  Â  Â  Â  code = getattr(getattr(e, 'response', None), 'status_code', 'unknown')
Â  Â  Â  Â  st.error(f"Google Sheets API error while loading '{worksheet}' (HTTP {code}). If 404/403, re-share the sheet with the service account and verify the ID.")
Â  Â  Â  Â  return pd.DataFrame()
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Unexpected error loading '{worksheet}': {type(e).__name__}: {e}")
Â  Â  Â  Â  return pd.DataFrame()

def _get_ws(tab: str):
Â  Â  """Return a Worksheet handle. (No caching; gspread objects aren't reliably cacheable.)"""
Â  Â  client = connect_to_gsheets()
Â  Â  if not client:
Â  Â  Â  Â  return None
Â  Â  ss = client.open_by_key(SPREADSHEET_ID) if SPREADSHEET_ID else client.open(GOOGLE_SHEET_NAME)
Â  Â  t = tab.strip()
Â  Â  try:
Â  Â  Â  Â  return ss.worksheet(t)
Â  Â  except WorksheetNotFound:
Â  Â  Â  Â  names = [w.title for w in ss.worksheets()]
Â  Â  Â  Â  norm = {n.strip().casefold(): n for n in names}
Â  Â  Â  Â  if t.casefold() in norm:
Â  Â  Â  Â  Â  Â  return ss.worksheet(norm[t.casefold()])
Â  Â  Â  Â  raise

# ---------- Sheet write helpers ----------
EXACT_HEADERS = [
Â  Â  "ISBN", "Title", "Author", "Genre", "Language", "Thumbnail", "Description", "Rating", "PublishedDate", "Date Read"
]

ISO_LANG = {
Â  Â  "EN":"English","IT":"Italian","ES":"Spanish","DE":"German","FR":"French",
Â  Â  "PT":"Portuguese","NL":"Dutch","SV":"Swedish","NO":"Norwegian","DA":"Danish",
Â  Â  "FI":"Finnish","RU":"Russian","PL":"Polish","TR":"Turkish","ZH":"Chinese",
Â  Â  "JA":"Japanese","KO":"Korean","AR":"Arabic","HE":"Hebrew","HI":"Hindi"
}

# Pretty language for 2- and 3-letter codes
ISO_LANG_2 = ISO_LANG.copy()
ISO_LANG_3 = {
Â  Â  "ENG":"English","ITA":"Italian","SPA":"Spanish","GER":"German","DEU":"German","FRE":"French","FRA":"French",
Â  Â  "POR":"Portuguese","NLD":"Dutch","DUT":"Dutch","SWE":"Swedish","NOR":"Norwegian","DAN":"Danish",
Â  Â  "FIN":"Finnish","RUS":"Russian","POL":"Polish","TUR":"Turkish","ZHO":"Chinese","JPN":"Japanese",
Â  Â  "KOR":"Korean","ARA":"Arabic","HEB":"Hebrew","HIN":"Hindi"
}

def _pretty_lang(code: str) -> str:
Â  Â  code = (code or "").strip().upper()
Â  Â  if not code:
Â  Â  Â  Â  return ""
Â  Â  if len(code) <= 3:
Â  Â  Â  Â  return ISO_LANG_2.get(code, code)
Â  Â  return ISO_LANG_3.get(code, code)

def normalize_language(s: str) -> str:
Â  Â  if not s:
Â  Â  Â  Â  return ""
Â  Â  s = str(s).strip()
Â  Â  if len(s) <= 3:
Â  Â  Â  Â  return ISO_LANG.get(s.upper(), s.upper())
Â  Â  return s

def _normalize_isbn(s: str) -> str:
Â  Â  if not s:
Â  Â  Â  Â  return ""
Â  Â  return "".join(ch for ch in str(s).replace("'", "") if ch.isdigit())

def keep_primary_author(author: str) -> str:
Â  Â  s = (author or "").strip()
Â  Â  if not s:
Â  Â  Â  Â  return ""
Â  Â  # If it's clearly a list of multiple people separated by commas (3+ parts), keep the first chunk
Â  Â  if s.count(',') >= 2:
Â  Â  Â  Â  return s.split(',')[0].strip()
Â  Â  # Trim lists joined by ' and ' or ' & '
Â  Â  if ' and ' in s:
Â  Â  Â  Â  return s.split(' and ')[0].strip()
Â  Â  if ' & ' in s:
Â  Â  Â  Â  return s.split(' & ')[0].strip()
Â  Â  return s

@st.cache_data(ttl=86400)
def _ol_fetch_json(url: str) -> dict:
Â  Â  try:
Â  Â  Â  Â  r = requests.get(url, timeout=12, headers=UA)
Â  Â  Â  Â  if r.ok:
Â  Â  Â  Â  Â  Â  return r.json()
Â  Â  except Exception:
Â  Â  Â  Â  pass
Â  Â  return {}

@st.cache_data(ttl=86400)
def get_openlibrary_rating(isbn: str):
Â  Â  """Return (avg, count) rating for the book's first work on Open Library, if any."""
Â  Â  try:
Â  Â  Â  Â  bj = _ol_fetch_json(f"https://openlibrary.org/isbn/{isbn}.json")
Â  Â  Â  Â  works = bj.get("works") or []
Â  Â  Â  Â  if not works:
Â  Â  Â  Â  Â  Â  return None, None
Â  Â  Â  Â  work_key = works[0].get("key")
Â  Â  Â  Â  if not work_key:
Â  Â  Â  Â  Â  Â  return None, None
Â  Â  Â  Â  rj = _ol_fetch_json(f"https://openlibrary.org{work_key}/ratings.json")
Â  Â  Â  Â  summary = rj.get("summary", {}) if isinstance(rj, dict) else {}
Â  Â  Â  Â  avg = summary.get("average")
Â  Â  Â  Â  count = summary.get("count")
Â  Â  Â  Â  return (avg, count)
Â  Â  except Exception:
Â  Â  Â  Â  return None, None

# ---------- Metadata fetchers (improved) ----------
@st.cache_data(ttl=86400)
def get_book_details_google(isbn: str) -> dict:
Â  Â  if not isbn:
Â  Â  Â  Â  return {}
Â  Â  try:
Â  Â  Â  Â  params = {"q": f"isbn:{isbn}", "printType": "books", "maxResults": 1}
Â  Â  Â  Â  if GOOGLE_BOOKS_KEY:
Â  Â  Â  Â  Â  Â  params["key"] = GOOGLE_BOOKS_KEY
Â  Â  Â  Â  r = requests.get(
Â  Â  Â  Â  Â  Â  "https://www.googleapis.com/books/v1/volumes",
Â  Â  Â  Â  Â  Â  params=params,
Â  Â  Â  Â  Â  Â  timeout=12,
Â  Â  Â  Â  Â  Â  headers=UA,
Â  Â  Â  Â  )
Â  Â  Â  Â  r.raise_for_status()
Â  Â  Â  Â  items = r.json().get("items", [])
Â  Â  Â  Â  if not items:
Â  Â  Â  Â  Â  Â  return {}
Â  Â  Â  Â  info = items[0].get("volumeInfo", {})
Â  Â  Â  Â  desc = info.get("description") or items[0].get("searchInfo", {}).get("textSnippet", "")
Â  Â  Â  Â  thumbs = info.get("imageLinks") or {}
Â  Â  Â  Â  thumb = thumbs.get("thumbnail") or thumbs.get("smallThumbnail") or ""
Â  Â  Â  Â  if thumb.startswith("http://"):
Â  Â  Â  Â  Â  Â  thumb = thumb.replace("http://", "https://")
Â  Â  Â  Â  cats = info.get("categories") or []
Â  Â  Â  Â  authors = info.get("authors") or []
Â  Â  Â  Â  author = keep_primary_author(authors[0].strip()) if authors else ""

Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "ISBN": isbn,
Â  Â  Â  Â  Â  Â  "Title": (info.get("title", "") or "").strip(),
Â  Â  Â  Â  Â  Â  "Author": author,
Â  Â  Â  Â  Â  Â  "Genre": ", ".join(cats) if cats else "",
Â  Â  Â  Â  Â  Â  "Language": (info.get("language") or "").upper(),
Â  Â  Â  Â  Â  Â  "Thumbnail": thumb,
Â  Â  Â  Â  Â  Â  "Description": (desc or "").strip(),
Â  Â  Â  Â  Â  Â  "Rating": str(info.get("averageRating", "")),
Â  Â  Â  Â  Â  Â  "PublishedDate": info.get("publishedDate", ""),
Â  Â  Â  Â  }
Â  Â  except Exception:
Â  Â  Â  Â  return {}

@st.cache_data(ttl=86400)
def get_book_details_openlibrary(isbn: str) -> dict:
Â  Â  try:
Â  Â  Â  Â  # Primary: jscmd=data
Â  Â  Â  Â  r = requests.get(
Â  Â  Â  Â  Â  Â  "https://openlibrary.org/api/books",
Â  Â  Â  Â  Â  Â  params={"bibkeys": f"ISBN:{isbn}", "jscmd": "data", "format": "json"},
Â  Â  Â  Â  Â  Â  timeout=12,
Â  Â  Â  Â  Â  Â  headers=UA,
Â  Â  Â  Â  )
Â  Â  Â  Â  r.raise_for_status()
Â  Â  Â  Â  data = r.json().get(f"ISBN:{isbn}") or {}

Â  Â  Â  Â  # Author(s)
Â  Â  Â  Â  authors_list = data.get("authors", [])
Â  Â  Â  Â  author = keep_primary_author(authors_list[0].get("name", "").strip()) if authors_list else ""

Â  Â  Â  Â  # Subjects -> Genre
Â  Â  Â  Â  subjects = ", ".join([s.get("name","") for s in data.get("subjects", []) if s])

Â  Â  Â  Â  # Cover
Â  Â  Â  Â  cover = (data.get("cover") or {}).get("large") \
Â Â  Â  Â  Â  Â  Â  or (data.get("cover") or {}).get("medium") \
Â Â  Â  Â  Â  Â  Â  or ""

Â  Â  Â  Â  # Description (varies across endpoints)
Â  Â  Â  Â  desc = data.get("description", "")
Â  Â  Â  Â  if isinstance(desc, dict):
Â  Â  Â  Â  Â  Â  desc = desc.get("value", "")

Â  Â  Â  Â  # Fallbacks via /isbn and works endpoint
Â  Â  Â  Â  bj = _ol_fetch_json(f"https://openlibrary.org/isbn/{isbn}.json") or {}
Â  Â  Â  Â  if not desc:
Â  Â  Â  Â  Â  Â  # Try work description
Â  Â  Â  Â  Â  Â  works = bj.get("works") or []
Â  Â  Â  Â  Â  Â  if works and works[0].get("key"):
Â  Â  Â  Â  Â  Â  Â  Â  wk = works[0]["key"]
Â  Â  Â  Â  Â  Â  Â  Â  wj = _ol_fetch_json(f"https://openlibrary.org{wk}.json") or {}
Â  Â  Â  Â  Â  Â  Â  Â  d = wj.get("description", "")
Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(d, dict):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  d = d.get("value", "")
Â  Â  Â  Â  Â  Â  Â  Â  desc = d or desc

Â  Â  Â  Â  if not cover:
Â  Â  Â  Â  Â  Â  # /isbn sometimes has a covers[] list of b-ids
Â  Â  Â  Â  Â  Â  if bj.get("covers"):
Â  Â  Â  Â  Â  Â  Â  Â  cover_id = bj["covers"][0]
Â  Â  Â  Â  Â  Â  Â  Â  cover = f"https://covers.openlibrary.org/b/id/{cover_id}-L.jpg"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Final ISBN-based cover attempt
Â  Â  Â  Â  Â  Â  Â  Â  cover = f"https://covers.openlibrary.org/b/isbn/{isbn}-L.jpg"

Â  Â  Â  Â  # Language
Â  Â  Â  Â  lang = ""
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  lang_key = (data.get("languages", [{}])[0].get("key"," ").split("/")[-1]).upper()
Â  Â  Â  Â  Â  Â  lang = lang_key
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  if not lang:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  langs = bj.get("languages", [])
Â  Â  Â  Â  Â  Â  Â  Â  if langs:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lang = (langs[0].get("key"," ").split("/")[-1] or "").upper()
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  lang = ""

Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "ISBN": isbn,
Â  Â  Â  Â  Â  Â  "Title": (data.get("title","") or "").strip(),
Â  Â  Â  Â  Â  Â  "Author": author,
Â  Â  Â  Â  Â  Â  "Genre": subjects,
Â  Â  Â  Â  Â  Â  "Language": lang,
Â  Â  Â  Â  Â  Â  "Thumbnail": cover or "",
Â  Â  Â  Â  Â  Â  "Description": (desc or "").strip(),
Â  Â  Â  Â  Â  Â  "PublishedDate": data.get("publish_date",""),
Â  Â  Â  Â  }
Â  Â  except Exception:
Â  Â  Â  Â  return {}

def get_goodreads_rating_placeholder(isbn: str) -> str:
Â  Â  return "GR:unavailable"

@st.cache_data(ttl=86400)
def get_book_metadata(isbn: str) -> dict:
Â  Â  google_meta = get_book_details_google(isbn)
Â  Â  openlibrary_meta = get_book_details_openlibrary(isbn)

Â  Â  # Prefer Google if it returned a title; fill gaps with OL
Â  Â  meta = google_meta.copy() if google_meta.get("Title") else openlibrary_meta.copy()

Â  Â  # Backfill from the other source where missing
Â  Â  for key in ["Title", "Author", "Genre", "Language", "Thumbnail", "Description", "PublishedDate"]:
Â  Â  Â  Â  if not meta.get(key):
Â  Â  Â  Â  Â  Â  meta[key] = openlibrary_meta.get(key, "") if meta is google_meta else google_meta.get(key, "")

Â  Â  # Ensure required keys exist
Â  Â  for k in ["ISBN","Title","Author","Genre","Language","Thumbnail","Description","Rating","PublishedDate"]:
Â  Â  Â  Â  meta.setdefault(k, "")

Â  Â  # Improve language readability
Â  Â  meta["Language"] = _pretty_lang(meta.get("Language", ""))

Â  Â  # Thumbnail: final fallback via OL ISBN cover
Â  Â  isbn = meta.get("ISBN", "")
Â  Â  if not meta.get("Thumbnail") and isbn:
Â  Â  Â  Â  meta["Thumbnail"] = f"https://covers.openlibrary.org/b/isbn/{isbn}-L.jpg"

Â  Â  # Ratings merge: Google + OpenLibrary + placeholder
Â  Â  ratings_parts = []
Â  Â  if google_meta.get("Rating"):
Â  Â  Â  Â  ratings_parts.append(f"GB:{google_meta['Rating']}")
Â  Â  ol_avg, _ = get_openlibrary_rating(isbn)
Â  Â  if ol_avg is not None:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  ratings_parts.append(f"OL:{round(float(ol_avg), 2)}")
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  ratings_parts.append(f"OL:{ol_avg}")
Â  Â  ratings_parts.append(get_goodreads_rating_placeholder(isbn))
Â  Â  meta["Rating"] = " | ".join(ratings_parts)

Â  Â  # Known name fix
Â  Â  if meta.get("Author") == "JÃ¸ Lier Horst":
Â  Â  Â  Â  meta["Author"] = "JÃ¸rn Lier Horst"

Â  Â  meta["Author"] = keep_primary_author(meta.get("Author", ""))

Â  Â  return meta

# ---------- Recommendations (two modes) ----------
@st.cache_data(ttl=86400)
def get_recommendations_by_author(author: str) -> list[dict]:
Â  Â  if not author:
Â  Â  Â  Â  return []
Â  Â  results: list[dict] = []

Â  Â  # Try Google Books first
Â  Â  try:
Â  Â  Â  Â  params = {"q": f"inauthor:{author}", "printType": "books", "maxResults": 20, "orderBy": "relevance"}
Â  Â  Â  Â  if GOOGLE_BOOKS_KEY:
Â  Â  Â  Â  Â  Â  params["key"] = GOOGLE_BOOKS_KEY
Â  Â  Â  Â  r = requests.get("https://www.googleapis.com/books/v1/volumes", params=params, timeout=12, headers=UA)
Â  Â  Â  Â  if r.ok:
Â  Â  Â  Â  Â  Â  for item in r.json().get("items", []) or []:
Â  Â  Â  Â  Â  Â  Â  Â  vi = item.get("volumeInfo", {})
Â  Â  Â  Â  Â  Â  Â  Â  isbn = ""
Â  Â  Â  Â  Â  Â  Â  Â  for ident in vi.get("industryIdentifiers", []) or []:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ident.get("type") in ("ISBN_13", "ISBN_10"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  isbn = ident.get("identifier", "")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  Â  Â  thumb = (vi.get("imageLinks") or {}).get("thumbnail", "")
Â  Â  Â  Â  Â  Â  Â  Â  if thumb.startswith("http://"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb = thumb.replace("http://", "https://")
Â  Â  Â  Â  Â  Â  Â  Â  results.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "source": "google",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "title": vi.get("title", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "authors": ", ".join(vi.get("authors", [])) if vi.get("authors") else "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "isbn": isbn,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "published": vi.get("publishedDate", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "description": vi.get("description", "") or "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "thumbnail": thumb,
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  except Exception:
Â  Â  Â  Â  pass

Â  Â  if results:
Â  Â  Â  Â  return results

Â  Â  # Fallback: OpenLibrary search
Â  Â  try:
Â  Â  Â  Â  ro = requests.get("https://openlibrary.org/search.json", params={"author": author, "limit": 20}, timeout=12, headers=UA)
Â  Â  Â  Â  if ro.ok:
Â  Â  Â  Â  Â  Â  data = ro.json()
Â  Â  Â  Â  Â  Â  for doc in data.get("docs", []) or []:
Â  Â  Â  Â  Â  Â  Â  Â  isbn = (doc.get("isbn") or [""])[0]
Â  Â  Â  Â  Â  Â  Â  Â  cover_id = doc.get("cover_i")
Â  Â  Â  Â  Â  Â  Â  Â  if cover_id:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb = f"https://covers.openlibrary.org/b/id/{cover_id}-M.jpg"
Â  Â  Â  Â  Â  Â  Â  Â  elif isbn:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb = f"https://covers.openlibrary.org/b/isbn/{isbn}-M.jpg"
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb = ""
Â  Â  Â  Â  Â  Â  Â  Â  results.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "source": "openlibrary",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "title": doc.get("title", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "authors": ", ".join(doc.get("author_name", []) or []),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "isbn": isbn,
Â  Â  Â  Â  Â  Â  Â  _de "published": str(doc.get("first_publish_year", "")),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "description": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "thumbnail": thumb,
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  except Exception:
Â  Â  Â  Â  pass

Â  Â  return results

# ---------- UI helpers ----------

def _cover_or_placeholder(url: str, title: str = "") -> tuple[str, str]:
Â  Â  url = (url or "").strip()
Â  Â  if url:
Â  Â  Â  Â  return url, title or ""
Â  Â  txt = quote((title or "No Cover").upper())
Â  Â  # Center text in placeholder by adding some line breaks
Â  Â  placeholder = f"https://via.placeholder.com/300x450?text={txt}"
Â  Â  return placeholder, (title or "No Cover")

# ---------- Sheet writer ----------

def append_record(tab: str, record: dict) -> None:
Â  Â  """Ensure headers, dedupe (ISBN or Title+Author), preserve ISBN as text, then append."""
Â  Â  try:
Â  Â  Â  Â  ws = _get_ws(tab)
Â  Â  Â  Â  if not ws:
Â  Â  Â  Â  Â  Â  raise RuntimeError("Worksheet not found")

Â  Â  Â  Â  headers = [h.strip() for h in ws.row_values(1)]
Â  Â  Â  Â  if not headers:
Â  Â  Â  Â  Â  Â  headers = EXACT_HEADERS[:]
Â  Â  Â  Â  Â  Â  ws.update('A1', [headers])
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  extras = [h for h in headers if h not in EXACT_HEADERS]
Â  Â  Â  Â  Â  Â  headers = EXACT_HEADERS[:] + extras
Â  Â  Â  Â  Â  Â  ws.update('A1', [headers])

Â  Â  Â  Â  values = ws.get_all_values()
Â  Â  Â  Â  existing_isbns, existing_ta = set(), set()
Â  Â  Â  Â  i_isbn = headers.index("ISBN") if "ISBN" in headers else None
Â  Â  Â  Â  i_title = headers.index("Title") if "Title" in headers else None
Â  Â  Â  Â  i_author = headers.index("Author") if "Author" in headers else None

Â  Â  Â  Â  for r in values[1:]:
Â  Â  Â  Â  Â  Â  if i_isbn is not None and len(r) > i_isbn:
Â  Â  Â  Â  Â  Â  Â  Â  norm = _normalize_isbn(r[i_isbn])
Â  Â  Â  Â  Â  Â  Â  Â  if norm:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  existing_isbns.add(norm)
Â  Â  Â  Â  Â  Â  if i_title is not None and i_author is not None and len(r) > max(i_title, i_author):
Â  Â  Â  Â  Â  Â  Â  Â  t = (r[i_title] or "").strip().lower()
Â  Â  Â  Â  Â  Â  Â  Â  a = (r[i_author] or "").strip().lower()
Â  Â  Â  Â  Â  Â  Â  Â  if t or a:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  existing_ta.add((t, a))

Â  Â  Â  Â  inc_isbn_norm = _normalize_isbn(record.get("ISBN", ""))
Â  Â  Â  Â  inc_ta = ((record.get("Title", "").strip().lower()), (record.get("Author", "").strip().lower()))

Â  Â  Â  Â  if inc_isbn_norm and inc_isbn_norm in existing_isbns:
Â  Â  Â  Â  Â  Â  st.info(f"'{record.get('Title','(unknown)')}' is already in {tab} (same ISBN). Skipped.")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  if inc_ta in existing_ta:
Â  Â  Â  Â  Â  Â  st.info(f"'{record.get('Title','(unknown)')}' by {record.get('Author','?')} is already in {tab}. Skipped.")
Â  Â  Â  Â  Â  Â  return

Â  Â  Â  Â  if record.get("ISBN") and str(record["ISBN"]).isdigit():
Â  Â  Â  Â  Â  Â  record["ISBN"] = "'" + str(record["ISBN"]).strip()

Â  Â  Â  Â  keymap = {h.lower(): h for h in headers}
Â  Â  Â  Â  row = [record.get(keymap.get(h.lower(), h), record.get(h, "")) for h in headers]
Â  Â  Â  Â  ws.append_row(row, value_input_option="USER_ENTERED")
Â  Â  Â  Â  st.cache_data.clear()

Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Failed to write to '{tab}': {e}")
Â  Â  Â  Â  raise

def update_gsheet_row(tab: str, row_index: int, record: dict) -> None:
Â  Â  """Finds a row by index and updates it with new data."""
Â  Â  try:
Â  Â  Â  Â  ws = _get_ws(tab)
Â  Â  Â  Â  if not ws:
Â  Â  Â  Â  Â  Â  raise RuntimeError(f"Worksheet '{tab}' not found.")

Â  Â  Â  Â  headers = ws.row_values(1)
Â  Â  Â  Â  if not headers:
Â  Â  Â  Â  Â  Â  st.error(f"Cannot update row: worksheet '{tab}' has no headers.")
Â  Â  Â  Â  Â  Â  return

Â  Â  Â  Â  # Ensure ISBN is stored as text
Â  Â  Â  Â  if "ISBN" in record and record.get("ISBN") and str(record["ISBN"]).isdigit():
Â  Â  Â  Â  Â  Â  record["ISBN"] = "'" + str(record["ISBN"]).strip()

Â  Â  Â  Â  # Map the record dictionary to a list in the correct header order
Â  Â  Â  Â  keymap = {h.lower(): h for h in headers}
Â  Â  Â  Â  row_values = [record.get(keymap.get(h.lower(), h), record.get(h, "")) for h in headers]

Â  Â  Â  Â  # Use gspread's update method with A1 notation for the entire row
Â  Â  Â  Â  ws.update(f'A{row_index}', [row_values], value_input_option="USER_ENTERED")
Â  Â  Â  Â  st.cache_data.clear() # Invalidate cache after writing
Â  Â  Â  Â  st.success(f"Row {row_index} in '{tab}' was updated successfully.")
Â  Â  Â  Â  # No st.rerun() here; let the calling function handle it.

Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Failed to update row {row_index} in '{tab}': {e}")
Â  Â  Â  Â  raise

# ---------- UI ----------

st.title("Misiddons Book Database")

# Initialize session state for form and scanner if not present
for k, v in {
Â  Â  "scan_isbn": "",
Â  Â  "scan_title": "",
Â  Â  "scan_author": "",
Â  Â  "last_scan_meta": {},
}.items():
Â  Â  st.session_state.setdefault(k, v)

# --- Add Book Form ---
with st.expander("âœï¸ Add a New Book Manually", expanded=False):
Â  Â  with st.form("entry_form"):
Â  Â  Â  Â  cols = st.columns(5)
Â  Â  Â  Â  title = cols[0].text_input("Title", value=st.session_state.get("scan_title", ""))
Â  Â  Â  Â  author = cols[1].text_input("Author", value=st.session_state.get("scan_author", ""))
Â  Â  Â  Â  isbn = cols[2].text_input("ISBN (Optional)", value=st.session_state.get("scan_isbn", ""))
Â  Â  Â  Â  date_read = cols[3].text_input("Date Read", placeholder="YYYY/MM/DD")
Â  Â  Â  Â  choice = cols[4].radio("Add to:", ["Library", "Wishlist"], horizontal=True)

Â  Â  Â  Â  if st.form_submit_button("Add Book"):
Â  Â  Â  Â  Â  Â  if title and author:
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  scan_meta = st.session_state.get("last_scan_meta", {})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec = {"ISBN": isbn, "Title": title, "Author": author, "Date Read": date_read}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in ["Genre","Language","Thumbnail","Description","Rating","PublishedDate"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if k in scan_meta and scan_meta[k]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec[k] = scan_meta[k]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Normalized de-dupe across both tabs
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lib_df = load_data("Library")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wish_df = load_data("Wishlist")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ensure expected columns exist to avoid KeyError
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for df in (lib_df, wish_df):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not df.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for col in ["ISBN","Title","Author"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if col not in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df[col] = ""

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_df = pd.concat([lib_df, wish_df], ignore_index=True) if not lib_df.empty or not wish_df.empty else pd.DataFrame(columns=["ISBN","Title","Author"])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  existing_isbns = set(all_df["ISBN"].astype(str).map(_normalize_isbn).dropna()) if not all_df.empty else set()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  existing_ta = set(zip(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_df.get("Title", pd.Series(dtype=str)).fillna("").str.strip().str.lower(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_df.get("Author", pd.Series(dtype=str)).fillna("").str.strip().str.lower(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )) if not all_df.empty else set()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inc_isbn_norm = _normalize_isbn(rec.get("ISBN",""))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inc_ta = (rec.get("Title","").strip().lower(), rec.get("Author","").strip().lower())

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if inc_isbn_norm and inc_isbn_norm in existing_isbns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"This book (ISBN: {rec.get('ISBN','')}) already exists in Library/Wishlist. Skipped.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif inc_ta in existing_ta:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"'{rec['Title']}' by {rec['Author']} already exists in Library/Wishlist. Skipped.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  append_record(choice, rec)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Added '{title}' to {choice} ğŸ‰")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Clear session state
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in ("scan_isbn","scan_title","scan_author"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[k] = ""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["last_scan_meta"] = {}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Failed to add book: {e}")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Enter both a title and author to add a book.")

# --- Barcode scanner (from image) ---
if zbar_decode:
Â  Â  with st.expander("ğŸ“· Scan Barcode from Photo", expanded=False):
Â  Â  Â  Â  up = st.file_uploader("Upload a clear photo of the barcode", type=["png", "jpg", "jpeg"])
Â  Â  Â  Â  if up:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  img = Image.open(up)
Â  Â  Â  Â  Â  Â  Â  Â  if img.mode != "RGB":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img = img.convert("RGB")
Â  Â  Â  Â  Â  Â  Â  Â  codes = zbar_decode(img)
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  codes = []

Â  Â  Â  Â  Â  Â  if not codes:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("No barcode found. Please try a closer, sharper photo.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  raw = codes[0].data.decode(errors="ignore")
Â  Â  Â  Â  Â  Â  Â  Â  # extract last 13 digits if present
Â  Â  Â  Â  Â  Â  Â  Â  digits = "".join(ch for ch in raw if ch.isdigit())
Â  Â  Â  Â  Â  Â  Â  Â  isbn_bc = digits[-13:] if len(digits) >= 13 else digits
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"Detected code: {raw} â†’ Using ISBN: {isbn_bc}")

Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Fetching book details..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  meta = get_book_metadata(isbn_bc)

Â  Â  Â  Â  Â  Â  Â  Â  if not meta or not meta.get("Title"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("Couldn't fetch details from Google/OpenLibrary. Check the ISBN or try again.")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["scan_isbn"] = meta.get("ISBN", "")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["scan_title"] = meta.get("Title", "")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["scan_author"] = meta.get("Author", "")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["last_scan_meta"] = meta

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols = st.columns([1, 3])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with cols[0]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cover_url, cap = _cover_or_placeholder(meta.get("Thumbnail",""), meta.get("Title",""))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(cover_url, caption=cap, width=150)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with cols[1]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader(meta.get("Title","Unknown Title"))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Author:** {meta.get('Author','Unknown')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Published Date:** {meta.get('PublishedDate','Unknown')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if meta.get("Rating"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Rating:** {meta.get('Rating')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if meta.get("Language"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Language:** {normalize_language(meta.get('Language'))}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_desc = meta.get("Description", "")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if full_desc:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lines = full_desc.split('\n')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(lines) > 5 or len(full_desc) > 500:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("Description (click to expand)"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(full_desc)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption(full_desc)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  a1, a2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with a1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("â• Add to Library", key="add_scan_lib", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  append_record("Library", meta)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Added to Library ğŸ‰")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in ("scan_isbn","scan_title","scan_author"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[k] = ""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["last_scan_meta"] = {}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with a2:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ§¾ Add to Wishlist", key="add_scan_wl", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  append_record("Wishlist", meta)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Added to Wishlist ğŸ“")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in ("scan_isbn","scan_title","scan_author"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[k] = ""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state["last_scan_meta"] = {}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass
else:
Â  Â  st.info("Barcode scanning requires `pyzbar`/`zbar`. If unavailable, paste the ISBN manually or use the manual form.")

st.divider()

# --- Tabs ---
tabs = st.tabs(["Library", "Wishlist", "Statistics", "Recommendations"])

with tabs[0]:
Â  Â  st.header("My Library")
Â  Â  library_df = load_data("Library")
Â  Â  if not library_df.empty:
Â  Â  Â  Â  search_lib = st.text_input("ğŸ” Search My Library...", placeholder="Search titles, authors, or genres...", key="lib_search")

Â  Â  Â  Â  lib_df_display = library_df.copy()
Â  Â  Â  Â  if search_lib:
Â  Â  Â  Â  Â  Â  lib_df_display = lib_df_display[
Â  Â  Â  Â  Â  Â  Â  Â  lib_df_display.apply(lambda row: row.astype(str).str.contains(search_lib, case=False, na=False).any(), axis=1)
Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  lib_df_display,
Â  Â  Â  Â  Â  Â  use_container_width=True,
Â  Â  Â  Â  Â  Â  column_config={
Â  Â  Â  Â  Â  Â  Â  Â  "Thumbnail": st.column_config.ImageColumn("Cover", width="small"),
Â  Â  Â  Â  Â  Â  Â  Â  "Description": st.column_config.TextColumn("Description", help="Summary of the book", width="large")
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  hide_index=True
Â  Â  Â  Â  )
Â  Â  else:
Â  Â  Â  Â  st.info("Your library is empty. Add a book to get started!")

with tabs[1]:
Â  Â  st.header("My Wishlist")
Â  Â  wishlist_df = load_data("Wishlist")
Â  Â  if not wishlist_df.empty:
Â  Â  Â  Â  search_wish = st.text_input("ğŸ” Search My Wishlist...", placeholder="Search titles, authors, or genres...", key="wish_search")

Â  Â  Â  Â  wish_df_display = wishlist_df.copy()
Â  Â  Â  Â  if search_wish:
Â  Â  Â  Â  Â  Â  wish_df_display = wish_df_display[
Â  Â  Â  Â  Â  Â  Â  Â  wish_df_display.apply(lambda row: row.astype(str).str.contains(search_wish, case=False, na=False).any(), axis=1)
Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  wish_df_display,
Â  Â  Â  Â  Â  Â  use_container_width=True,
Â  Â  Â  Â  Â  Â  column_config={
Â  Â  Â  Â  Â  Â  Â  Â  "Thumbnail": st.column_config.ImageColumn("Cover", width="small"),
Â  Â  Â  Â  Â  Â  Â  Â  "Description": st.column_config.TextColumn("Description", help="Summary of the book", width="large")
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  hide_index=True
Â  Â  Â  Â  )
Â  Â  else:
Â  Â  Â  Â  st.info("Your wishlist is empty. Scan a book or add one manually!")

with tabs[2]:
Â  Â  st.header("Statistics")
Â  Â  library_df = load_data("Library")
Â  Â  wishlist_df = load_data("Wishlist")

Â  Â  col1, col2, col3 = st.columns(3)
Â  Â  with col1:
Â  Â  Â  Â  st.metric("Total Books in Library", len(library_df))
Â  Â  with col2:
Â  Â  Â  Â  st.metric("Total Books on Wishlist", len(wishlist_df))
Â  Â  with col3:
Â  Â  Â  Â  uniq_auth = 0 if library_df.empty or "Author" not in library_df.columns else library_df["Author"].fillna("").astype(str).str.split(",").explode().str.strip().replace({"": None}).dropna().nunique()
Â  Â  Â  Â  st.metric("Unique Authors (Library)", int(uniq_auth))

with tabs[3]:
Â  Â  st.header("Recommendations")
Â  Â  library_df = load_data("Library")
Â  Â  wishlist_df = load_data("Wishlist")

Â  Â  # Collect owned titles/ISBNs to filter out
Â  Â  owned_titles = set()
Â  Â  owned_isbns = set()
Â  Â  for df in (library_df, wishlist_df):
Â  Â  Â  Â  if not df.empty:
Â  Â  Â  Â  Â  Â  if "Title" in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  owned_titles.update(df["Title"].dropna().astype(str).str.lower().str.strip().tolist())
Â  Â  Â  Â  Â  Â  if "ISBN" in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  owned_isbns.update(df["ISBN"].dropna().astype(str).map(_normalize_isbn).tolist())

Â  Â  # Build author list from Library
Â  Â  authors = []
Â  Â  if not library_df.empty and "Author" in library_df.columns:
Â  Â  Â  Â  authors = (
Â  Â  Â  Â  Â  Â  library_df["Author"].dropna()
Â  Â  Â  Â  Â  Â  .astype(str)
Â  Â  Â  Â  Â  Â  .str.split(",")
Â  Â  Â  Â  Â  Â  .explode()
Â  Â  Â  Â  Â  Â  .str.strip()
Â  Â  Â  Â  Â  Â  .replace({"": None})
Â  Â  Â  Â  Â  Â  .dropna()
Â  Â  Â  Â  Â  Â  .unique()
Â  Â  Â  Â  Â  Â  .tolist()
Â  Â  Â  Â  )
Â  Â  Â  Â  authors = sorted(set(authors), key=lambda s: s.lower())

Â  Â  mode = st.radio("Recommendation mode:", ["Surprise me (4 random unseen)", "By author"], horizontal=True)

Â  Â  if mode == "By author":
Â  Â  Â  Â  if authors:
Â  Â  Â  Â  Â  Â  selected_author = st.selectbox("Find books by authors you've read:", authors)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  selected_author = st.text_input("Type an author to get recommendations:")

Â  Â  Â  Â  if selected_author:
Â  Â  Â  Â  Â  Â  recommendations = get_recommendations_by_author(selected_author)

Â  Â  Â  Â  Â  Â  shown = 0
Â  Â  Â  Â  Â  Â  for item in recommendations:
Â  Â  Â  Â  Â  Â  Â  Â  title = (item.get("title") or "").strip()
Â  Â  Â  Â  Â  Â  Â  Â  isbn = _normalize_isbn(item.get("isbn", ""))
Â  Â  Â  Â  Â  Â  Â  Â  if (title.lower() in owned_titles) or (isbn and isbn in owned_isbns):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  cols = st.columns([1, 4])
Â  Â  Â  Â  Â  Â  Â  Â  with cols[0]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb, _ = _cover_or_placeholder(item.get("thumbnail", ""), title)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(thumb, width=100)
Â  Â  Â  Â  Â  Â  Â  Â  with cols[1]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader(title or "No Title")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Author(s):** {item.get('authors', 'N/A')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Published:** {item.get('published', 'N/A')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if item.get("description"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption(item["description"])Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Add to Wishlist button per recommendation
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  add_key = f"rec_add_{selected_author}_{shown}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ§¾ Add to Wishlist", key=add_key):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec_meta = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ISBN": isbn, "Title": title, "Author": item.get("authors", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Thumbnail": item.get("thumbnail", ""), "Description": (item.get("description") or ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "PublishedDate": item.get("published", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  append_record("Wishlist", rec_meta)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Added '{title}' to Wishlist")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Could not add: {e}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  Â  Â  shown += 1
Â  Â  Â  Â  Â  Â  Â  Â  if shown >= 5:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  if shown == 0:
Â  Â  Â  Â  Â  Â  Â  Â  st.info("No new recommendations found. Try another author.")

Â  Â  else:Â  # Surprise me (4 random unseen)
Â  Â  Â  Â  if not authors:
Â  Â  Â  Â  Â  Â  st.info("Add books to your Library to get surprise recommendations.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  sample_authors = random.sample(authors, k=min(6, len(authors)))
Â  Â  Â  Â  Â  Â  pool: list[dict] = []
Â  Â  Â  Â  Â  Â  for a in sample_authors:
Â  Â  Â  Â  Â  Â  Â  Â  pool.extend(get_recommendations_by_author(a))
Â  Â  Â  Â  Â  Â  filtered = []
Â  Â  Â  Â  Â  Â  for item in pool:
Â  Â  Â  Â  Â  Â  Â  Â  title = (item.get("title") or "").strip()
Â  Â  Â  Â  Â  Â  Â  Â  isbn = _normalize_isbn(item.get("isbn", ""))
Â  Â  Â  Â  Â  Â  Â  Â  if not title or (title.lower() in owned_titles) or (isbn and isbn in owned_isbns):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  filtered.append(item)
Â  Â  Â  Â  Â  Â  random.shuffle(filtered)
Â  Â  Â  Â  Â  Â  picks = filtered[:4]

Â  Â  Â  Â  Â  Â  if not picks:
Â  Â  Â  Â  Â  Â  Â  Â  st.info("Couldn't find unseen picks right now. Try 'By author' mode.")
Â  Â  Â  Â  Â  Â  for idx, item in enumerate(picks, 1):
Â  Â  Â  Â  Â  Â  Â  Â  title = (item.get("title") or "").strip()
Â  Â  Â  Â  Â  Â  Â  Â  cols = st.columns([1, 4])
Â  Â  Â  Â  Â  Â  Â  Â  with cols[0]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thumb, _ = _cover_or_placeholder(item.get("thumbnail", ""), title)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(thumb, width=100)
Â  Â  Â  Â  Â  Â  Â  Â  with cols[1]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader(f"{idx}. {title or 'No Title'}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Author(s):** {item.get('authors', 'N/A')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"**Published:** {item.get('published', 'N/A')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if item.get("description"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption(item["description"])Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  isbn = _normalize_isbn(item.get("isbn", ""))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  add_key = f"rec_surprise_add_{idx}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ§¾ Add to Wishlist", key=add_key):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec_meta = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ISBN": isbn, "Title": title, "Author": item.get("authors", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Thumbnail": item.get("thumbnail", ""), "Description": (item.get("description") or ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "PublishedDate": item.get("published", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  append_record("Wishlist", rec_meta)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Added '{title}' to Wishlist")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Could not add: {e}")
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")

# ---- Diagnostics and Data Cleaning Tools ----
st.divider()
st.header("Data Health & Diagnostics")

with st.expander("Connection Diagnostics"):
Â  Â  try:
Â  Â  Â  Â  acct = st.secrets.get("gcp_service_account", {}).get("client_email", "(missing)")
Â  Â  Â  Â  st.write("Service account email:", acct)
Â  Â  Â  Â  st.write("Spreadsheet ID in use:", SPREADSHEET_ID)
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  test_client = connect_to_gsheets()
Â  Â  Â  Â  Â  Â  if test_client:
Â  Â  Â  Â  Â  Â  Â  Â  ss = test_client.open_by_key(SPREADSHEET_ID) if SPREADSHEET_ID else test_client.open(GOOGLE_SHEET_NAME)
Â  Â  Â  Â  Â  Â  Â  Â  st.write("Found worksheet tabs:", [w.title for w in ss.worksheets()])
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  st.write("Open spreadsheet error:", f"{type(e).__name__}: {e}")
Â  Â  except Exception as e:
Â  Â  Â  Â  st.write("Diagnostics error:", f"{type(e).__name__}: {e}")

# ==== Data Check (Library) =====================================================
with st.expander("ğŸ” Data Check â€” Library (Find Issues)", expanded=False):
Â  Â  lib = load_data("Library")

Â  Â  if lib.empty:
Â  Â  Â  Â  st.info("Library sheet is empty.")
Â  Â  else:
Â  Â  Â  Â  # Ensure expected columns exist
Â  Â  Â  Â  for c in ["ISBN", "Title", "Author", "Language", "Thumbnail", "PublishedDate", "Date Read", "Description"]:
Â  Â  Â  Â  Â  Â  if c not in lib.columns:
Â  Â  Â  Â  Â  Â  Â  Â  lib[c] = ""
Â  Â  Â  Â  lib["_isbn_norm"] Â  = lib["ISBN"].astype(str).map(_normalize_isbn)
Â  Â  Â  Â  lib["_author_primary"] = lib["Author"].astype(str).map(keep_primary_author)
Â  Â  Â  Â  lib["_title_norm"]Â  = lib["Title"].astype(str).str.strip().str.lower()
Â  Â  Â  Â  lib["_ta_key"]Â  Â  Â  = lib["_title_norm"] + " | " + lib["_author_primary"].str.strip().str.lower()
Â  Â  Â  Â  issues = []
Â  Â  Â  Â  mask_missing = (lib["Title"].astype(str).str.strip() == "") | (lib["Author"].astype(str).str.strip() == "")
Â  Â  Â  Â  for i, r in lib[mask_missing].iterrows():
Â  Â  Â  Â  Â  Â  issues.append({"Row": i+2, "Issue": "Missing Title or Author", "Title": r["Title"], "Author": r["Author"], "ISBN": r["ISBN"], "Suggestion": "Fill in missing field(s)."})
Â  Â  Â  Â  mask_author_multi = lib["Author"].astype(str) != lib["_author_primary"]
Â  Â  Â  Â  for i, r in lib[mask_author_multi].iterrows():
Â  Â  Â  Â  Â  Â  issues.append({"Row": i+2, "Issue": "Author list not normalized", "Title": r["Title"], "Author": r["Author"], "ISBN": r["ISBN"], "Suggestion": f"Use primary author â†’ '{r['_author_primary']}'."})
Â  Â  Â  Â  dup_isbn = lib[lib["_isbn_norm"] != ""][lib["_isbn_norm"].duplicated(keep=False)].sort_values("_isbn_norm")
Â  Â  Â  Â  for i, r in dup_isbn.iterrows():
Â  Â  Â  Â  Â  Â  issues.append({"Row": i+2, "Issue": "Duplicate ISBN", "Title": r["Title"], "Author": r["_author_primary"], "ISBN": r["ISBN"], "Suggestion": "Remove duplicate or correct ISBN."})
Â  Â  Â  Â  dup_ta = lib[lib["_ta_key"].duplicated(keep=False)].sort_values("_ta_key")
Â  Â  Â  Â  for i, r in dup_ta.iterrows():
Â  Â  Â  Â  Â  Â  issues.append({"Row": i+2, "Issue": "Duplicate Title+Author", "Title": r["Title"], "Author": r["_author_primary"], "ISBN": r["ISBN"], "Suggestion": "Remove duplicate row."})
Â  Â  Â  Â  bad_thumb = lib["Thumbnail"].astype(str).str.startswith("http://", na=False)
Â  Â  Â  Â  for i, r in lib[bad_thumb].iterrows():
Â  Â  Â  Â  Â  Â  issues.append({"Row": i+2, "Issue": "Insecure cover URL (http)", "Title": r["Title"], "Author": r["_author_primary"], "ISBN": r["ISBN"], "Suggestion": "Switch to https:// thumbnail."})
Â  Â  Â  Â  if issues:
Â  Â  Â  Â  Â  Â  prob_df = pd.DataFrame(issues, columns=["Row","Issue","Title","Author","ISBN","Suggestion"])
Â  Â  Â  Â  Â  Â  st.warning(f"Found {len(prob_df)} potential issue(s).")
Â  Â  Â  Â  Â  Â  st.dataframe(prob_df, use_container_width=True, hide_index=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.success("Looks good! No basic issues detected in Library ğŸ‰")

# ==== Normalization Helpers for Cross-Check ===================================
def _strip_diacritics(s: str) -> str:
Â  Â  return unicodedata.normalize("NFKD", s or "").encode("ascii", "ignore").decode()

def _norm_text_for_compare(s: str, is_title: bool = True) -> str:
Â  Â  s = _strip_diacritics(str(s))
Â  Â  if is_title:
Â  Â  Â  Â  s = re.split(r"[:(\\[]", s, 1)[0]
Â  Â  Â  Â  s = re.sub(r"\\b(a|an|the)\\b\\s+", "", s, flags=re.I)
Â  Â  else: # author
Â  Â  Â  Â  s = keep_primary_author(s)
Â  Â  s = re.sub(r"[^a-z0-9 ]+", " ", s.lower())
Â  Â  return re.sub(r"\\s+", " ", s).strip()


# ==== NEW: Interactive Data Deep-Clean & Repair =================================
with st.expander("ğŸ› ï¸ Data Deep-Clean & Repair (Library)", expanded=False):
Â  Â  st.info("This tool checks each book (with an ISBN) against online sources to find and fix errors like misspelled titles, missing covers, and more.", icon="â„¹ï¸")
Â  Â  if st.button("Start Deep-Clean & Repair", key="start_deep_clean"):
Â  Â  Â  Â  lib = load_data("Library")
Â  Â  Â  Â  if lib.empty:
Â  Â  Â  Â  Â  Â  st.info("Library is empty. Nothing to clean.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  required_cols = ["ISBN", "Title", "Author", "Description", "Language", "Thumbnail"]
Â  Â  Â  Â  Â  Â  for c in required_cols:
Â  Â  Â  Â  Â  Â  Â  Â  if c not in lib.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lib[c] = ""
Â  Â  Â  Â  Â  Â  lib = lib.fillna("") # Replace NaN with empty strings for easier comparison

Â  Â  Â  Â  Â  Â  issues_found = 0
Â  Â  Â  Â  Â  Â  with st.spinner("Cross-referencing your library... This may take a moment."):
Â  Â  Â  Â  Â  Â  Â  Â  for i, row in lib.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sheet_data = row.to_dict()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sheet_row_index = i + 2 # Google Sheet is 1-indexed, +1 for header
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  isbn = _normalize_isbn(str(sheet_data.get("ISBN", "")))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not isbn:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue # This tool relies on ISBN for reliable metadata

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  canonical_data = get_book_metadata(isbn)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not canonical_data.get("Title"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mismatches = {}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nt_s = _norm_text_for_compare(sheet_data.get("Title", ""), is_title=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  nt_c = _norm_text_for_compare(canonical_data.get("Title", ""), is_title=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if SequenceMatcher(None, nt_s, nt_c).ratio() < 0.95:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mismatches['Title'] = {'sheet': sheet_data.get("Title"), 'canonical': canonical_data.get("Title")}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  na_s = _norm_text_for_compare(sheet_data.get("Author", ""), is_title=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  na_c = _norm_text_for_compare(canonical_data.get("Author", ""), is_title=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if SequenceMatcher(None, na_s, na_c).ratio() < 0.95:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mismatches['Author'] = {'sheet': sheet_data.get("Author"), 'canonical': canonical_data.get("Author")}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for field in ["Description", "Language", "Thumbnail"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not str(sheet_data.get(field, "")).strip() and str(canonical_data.get(field, "")).strip():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mismatches[field] = {'sheet': '(empty)', 'canonical': canonical_data.get(field)}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if mismatches:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  issues_found += 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"**Issue found in Row {sheet_row_index}: *{sheet_data.get('Title')}***")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for field, values in mismatches.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_sheet = str(values['sheet'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_canon = str(values['canonical'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(val_sheet) > 150: val_sheet = val_sheet[:150] + '...'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(val_canon) > 150: val_canon = val_canon[:150] + '...'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  c1.markdown(f"**{field} (Current):**\n`{val_sheet}`")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  c2.markdown(f"**{field} (Suggestion):**\n`{val_canon}`")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  update_key = f"update_row_{sheet_row_index}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("âœ… Accept & Update Row", key=update_key):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  corrected_record = sheet_data.copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for field, values in mismatches.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  corrected_record[field] = values['canonical']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  update_gsheet_row("Library", sheet_row_index, corrected_record)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Error is already displayed by the update function
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  if issues_found == 0:
Â  Â  Â  Â  Â  Â  Â  Â  st.success("âœ¨ Deep-clean complete. No major issues found!")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"Scan complete. Found {issues_found} entries with potential issues to correct.")
